{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gym_environment\n",
    "env = gym_environment.Environment()\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_LAYER_SIZE = 128\n",
    "class DQN(nn.Module):\n",
    "\tdef __init__(self, observation_size, action_size):\n",
    "\t\tsuper().__init__()\n",
    "\t\t# self.fc1 = nn.Linear(observation_size, HIDDEN_LAYER_SIZE)\n",
    "\t\t# self.fc2 = nn.Linear(HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE)\n",
    "\t\t# self.fc3 = nn.Linear(HIDDEN_LAYER_SIZE, action_size)\n",
    "\t\tself.fc1 = nn.Linear(observation_size, 32)\n",
    "\t\tself.fc2 = nn.Linear(32, 64)\n",
    "\t\tself.fc3 = nn.Linear(64, 128)\n",
    "\t\tself.fc4 = nn.Linear(128, action_size)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\tx = F.relu(self.fc2(x))\n",
    "\t\tx = F.relu(self.fc3(x))\n",
    "\t\treturn self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "action_size = env.action_space.n\n",
    "state, _ = env.reset()\n",
    "observation_size = len(state)\n",
    "\n",
    "policy_net = DQN(observation_size, action_size).to(device)\n",
    "target_net = DQN(observation_size, action_size).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "steps_done = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(states):\n",
    "\tglobal steps_done\n",
    "\tsample = random.random()\n",
    "\teps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "\tsteps_done += 1\n",
    "\tif sample > eps_threshold:\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\t# t.max(1) will return the largest column value of each row.\n",
    "\t\t\t# second column on max result is index of where max element was\n",
    "\t\t\t# found, so we pick action with the larger expected reward.\n",
    "\t\t\treturn torch.tensor([policy_net(state).max(1).indices.view(1, 1) for state in states])\n",
    "\telse:\n",
    "\t\treturn torch.tensor([env.action_space.sample() for _ in states], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[   24.3320,    25.7675,    18.2000, -1000.0000,     0.0000],\n",
      "         [   21.0030,    24.3094,    18.2000, -1000.0000,     0.0000],\n",
      "         [   21.9013,    20.8434,    18.2000, -1000.0000,     0.0000],\n",
      "         [   27.5019,    24.7187,    18.2000, -1000.0000,     0.0000],\n",
      "         [   26.2069,    27.7910,    18.2000, -1000.0000,     0.0000]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1049405/3761681083.py:75: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "take(): argument 'index' (position 2) must be Tensor, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m count():\n\u001b[1;32m     80\u001b[0m \taction \u001b[38;5;241m=\u001b[39m select_action(state)\n\u001b[0;32m---> 81\u001b[0m \tobservation, reward, terminated \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \t\u001b[38;5;66;03m# temps[t] = env._cur_temp\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \t\u001b[38;5;66;03m# target[t] = env._target\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \t\u001b[38;5;66;03m# reward2[t] = reward\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \treward \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([reward], device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Desktop/Programs/thing/gym_environment.py:56\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[0;34m(self, power)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setpoint_list:\n\u001b[1;32m     53\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_setpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setpoint_list[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_temp \u001b[38;5;241m=\u001b[39m sim\u001b[38;5;241m.\u001b[39mcalc_next_temp(\n\u001b[0;32m---> 56\u001b[0m \t\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpower\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     57\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cur_temp,\n\u001b[1;32m     58\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_reward()\n\u001b[1;32m     62\u001b[0m terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length\n",
      "\u001b[0;31mTypeError\u001b[0m: take(): argument 'index' (position 2) must be Tensor, not int"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import const\n",
    "\n",
    "def my_optimize_model():\n",
    "\tif len(memory) < BATCH_SIZE:\n",
    "\t\treturn\n",
    "\t\n",
    "\ttransitions = memory.sample(BATCH_SIZE)\n",
    "\n",
    "\n",
    "def optimize_model():\n",
    "\tif len(memory) < BATCH_SIZE:\n",
    "\t\treturn\n",
    "\t\n",
    "\ttransitions = memory.sample(BATCH_SIZE)\n",
    "\tbatch = Transition(*zip(*transitions))\n",
    "\t# print(batch)\n",
    "\n",
    "\tnon_final_mask = torch.tensor(list(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "\tnon_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "\n",
    "\tstate_batch = torch.cat(batch.state)\n",
    "\taction_batch = torch.cat(batch.action)\n",
    "\treward_batch = torch.cat(batch.reward)\n",
    "\n",
    "\t# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "\t# columns of actions taken. These are the actions which would've been taken\n",
    "\t# for each batch state according to policy_net\n",
    "\tstate_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "\t# Compute V(s_{t+1}) for all next states.\n",
    "\t# Expected values of actions for non_final_next_states are computed based\n",
    "\t# on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "\t# This is merged based on the mask, such that we'll have either the expected\n",
    "\t# state value or 0 in case the state was final.\n",
    "\tnext_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "\twith torch.no_grad():\n",
    "\t\tnext_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "\t# Compute the expected Q values\n",
    "\texpected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "\t# Compute Huber loss\n",
    "\tcriterion = nn.SmoothL1Loss()\n",
    "\tloss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "\t# Optimize the model\n",
    "\toptimizer.zero_grad()\n",
    "\tloss.backward()\n",
    "\t# In-place gradient clipping\n",
    "\ttorch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "\toptimizer.step()\n",
    "\n",
    "\n",
    "if torch.cuda.is_available() or torch.backends.mps.is_available():\n",
    "\tnum_episodes = 600\n",
    "else:\n",
    "\tnum_episodes = 600\n",
    "\n",
    "# num_episodes = 1\n",
    "\n",
    "xvalues = np.arange(1441)\n",
    "temps = np.zeros(1441)\n",
    "target = np.zeros(1441)\n",
    "reward2 = np.zeros(1441)\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "\trewards = []\n",
    "\ttotal_reward = 0\n",
    "\t# Initialize the environment and get its state\n",
    "\n",
    "\tweather_start = random.randrange(0, len(const.OUTSIDE_TEMP) - 1440)\n",
    "\tstate, info = env.reset(num_setpoints=random.randint(2, 7), start_time=weather_start)\n",
    "\t\n",
    "\tstate = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "\tprint(state)\n",
    "\n",
    "\tfor t in count():\n",
    "\t\taction = select_action(state)\n",
    "\t\tobservation, reward, terminated = env.step(action.item())\n",
    "\n",
    "\t\t# temps[t] = env._cur_temp\n",
    "\t\t# target[t] = env._target\n",
    "\t\t# reward2[t] = reward\n",
    "\n",
    "\t\treward = torch.tensor([reward], device=device)\n",
    "\t\tdone = terminated \n",
    "\n",
    "\t\tif terminated:\n",
    "\t\t\tnext_state = None\n",
    "\t\telse:\n",
    "\t\t\tnext_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "\t\t# Store the transition in memory\n",
    "\t\tmemory.push(state, action, next_state, reward)\n",
    "\n",
    "\t\t# Move to the next state\n",
    "\t\tstate = next_state\n",
    "\n",
    "\t\t# Perform one step of the optimization (on the policy network)\n",
    "\t\toptimize_model()\n",
    "\n",
    "\t\t# Soft update of the target network's weights\n",
    "\t\t# θ′ ← τ θ + (1 −τ )θ′\n",
    "\t\ttarget_net_state_dict = target_net.state_dict()\n",
    "\t\tpolicy_net_state_dict = policy_net.state_dict()\n",
    "\t\tfor key in policy_net_state_dict:\n",
    "\t\t\ttarget_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "\t\ttarget_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "\t\trewards.append(reward.item())\n",
    "\t\tif done:\n",
    "\t\t\tprint(f\"{' ' * 200}\\repisode {i_episode} sum {sum(rewards)}\", end=\"\\r\")\n",
    "\t\t\tbreak\n",
    "\n",
    "# plt.plot(xvalues, temps, linewidth=0.1)\n",
    "# plt.plot(xvalues, target, linewidth=0.1)\n",
    "# plt.plot(xvalues, reward2, linewidth=0.1)\n",
    "# plt.ioff()\n",
    "# plt.savefig(\"out.png\", dpi=3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: tensor([20.3548, 20.9895, 22.2106,  ..., 23.8111, 26.3261, 24.0288]), 260: tensor([20.3691, 22.5655, 25.0769,  ..., 24.7161, 25.4532, 25.7536]), 338: tensor([26.4366, 25.0083, 21.8400,  ..., 25.7647, 22.2100, 24.2755]), 832: tensor([22.6826, 22.9927, 24.6366,  ..., 22.2752, 20.8311, 20.8358]), 901: tensor([24.1880, 24.6677, 27.9468,  ..., 27.9965, 25.1879, 20.4541])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[   20.5346,    20.3548,    18.2000, -1000.0000,     0.0000],\n",
       "         [   27.5385,    20.9895,    18.2000, -1000.0000,     0.0000],\n",
       "         [   26.8875,    22.2106,    18.2000, -1000.0000,     0.0000],\n",
       "         ...,\n",
       "         [   27.7921,    23.8111,    18.2000, -1000.0000,     0.0000],\n",
       "         [   20.8296,    26.3261,    18.2000, -1000.0000,     0.0000],\n",
       "         [   23.2396,    24.0288,    18.2000, -1000.0000,     0.0000]]),\n",
       " tensor([-0.1797, -6.5489, -4.6770,  ..., -3.9810, -5.4965, -0.7893]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym_environment\n",
    "env = gym_environment.Environment()\n",
    "env.reset(num_setpoints=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(policy_net.state_dict(), \"combination_3k_2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net.load_state_dict(torch.load('subtract_4_3k.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m cycles \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     32\u001b[0m deviation_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 34\u001b[0m state, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mreset(num_setpoints\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, length\u001b[38;5;241m=\u001b[39msim_max, start_time\u001b[38;5;241m=\u001b[39mweather_start)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sim_max):\t\n\u001b[1;32m     37\u001b[0m \tpower \u001b[38;5;241m=\u001b[39m policy_net(torch\u001b[38;5;241m.\u001b[39mtensor([state]))\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import const\n",
    "import random\n",
    "import time\n",
    "import agents.dumb_agent\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_xlabel(\"time (min)\")\n",
    "# ax1.set_ylim(10, 30)\n",
    "# ax1.set_yticks(np.arange(10, 31))\n",
    "ax1.set_ylabel(\"deg C\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylim(-1, 5)\n",
    "ax2.set_ylabel(\"mean temp deviation or ac/heater power\")\n",
    "\n",
    "sim_max = 2880\n",
    "\n",
    "# weather_start = 695991\n",
    "weather_start = random.randrange(0, len(const.OUTSIDE_TEMP) - sim_max)\n",
    "\n",
    "xvalues = np.arange(0, sim_max)\n",
    "temperatures = np.zeros(sim_max)\n",
    "setpoints = np.zeros(sim_max)\n",
    "outside_temp = np.zeros(sim_max)\n",
    "on_off = np.zeros(sim_max)\n",
    "mean_dev = np.zeros(sim_max)\n",
    "old_action = 0\n",
    "cycles = 0\n",
    "\n",
    "deviation_sum = 0\n",
    "\n",
    "state, _ = env.reset(num_setpoints=5, length=sim_max, start_time=weather_start)\n",
    "\n",
    "for i in range(sim_max):\t\n",
    "\tpower = policy_net(torch.tensor([state])).max(1).indices.view(1, 1).item()\n",
    "\t# power = agents.dumb_agent.agent(env.get_cur_temp(), const.OUTSIDE_TEMP[weather_start + i], env.get_setpoint(), [-1, -0.75, -0.5, -0.25, 0, 1][old_action])\n",
    "\t# power = [-1, -0.75, -0.5, -0.25, 0, 1].index(power)\n",
    "\tif env._sgn(power) != env._sgn(old_action):\n",
    "\t\tcycles += 1\n",
    "\told_action = power\n",
    "\n",
    "\ttemperatures[i] = env.get_cur_temp()\n",
    "\tsetpoints[i] = env.get_setpoint()\n",
    "\toutside_temp[i] = const.OUTSIDE_TEMP[weather_start + i]\n",
    "\n",
    "\ton_off[i] = env._actions[power]\n",
    "\n",
    "\tdeviation_sum += abs(temperatures[i] - env.get_setpoint())\n",
    "\tstate, reward, _ = env.step(power)\n",
    "\n",
    "\tmean_dev[i] = deviation_sum / (i + 1)\n",
    "\n",
    "ax1.plot(xvalues, temperatures, color=\"red\", linewidth=0.1)\n",
    "ax1.plot(xvalues, setpoints, color=\"blue\", linewidth=0.1)\n",
    "ax1.plot(xvalues, outside_temp, color=\"green\", linewidth=0.1)\n",
    "ax2.plot(xvalues, on_off, color=\"black\", linewidth=0.1)\n",
    "ax2.plot(xvalues, mean_dev, color=\"purple\", linewidth=0.1)\n",
    "# plt.show()\n",
    "plt.savefig(\"old2.png\", dpi=1000)\n",
    "\n",
    "cycles\n",
    "# m2K/W * m2 * K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import agents.dumb_agent\n",
    "import const\n",
    "import random\n",
    "import time\n",
    "import agents.pid_agent\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.set_ylabel(\"deg C\")\n",
    "\n",
    "# ax2 = ax1.twinx()\n",
    "# ax2.set_ylabel(\"cycles\")\n",
    "\n",
    "episode_count = 100\n",
    "sim_max = 2880\n",
    "num_setpoints = 5\n",
    "\n",
    "xvalues = np.arange(episode_count)\n",
    "stupid_dev = np.zeros(episode_count)\n",
    "stupid_cycles = np.zeros(episode_count)\n",
    "dqn_dev = np.zeros(episode_count)\n",
    "dqn_cycles = np.zeros(episode_count)\n",
    "\n",
    "for i in range(episode_count):\n",
    "\tdeviation_sum = 0\n",
    "\t# weather_start = 0\n",
    "\tweather_start = random.randrange(0, len(const.OUTSIDE_TEMP) - sim_max)\n",
    "\tstate, _ = env.reset(num_setpoints=num_setpoints, length=sim_max, start_time=weather_start)\n",
    "\told_action = 0\n",
    "\tcycles = 0\n",
    "\tfor t in range(sim_max):\t\n",
    "\t\tpower = policy_net(torch.tensor([state])).max(1).indices.view(1, 1).item()\n",
    "\t\tif env._sgn(power) != env._sgn(old_action):\n",
    "\t\t\tcycles += 1\n",
    "\t\told_action = power\n",
    "\n",
    "\t\tdeviation_sum += abs(env.get_cur_temp() - env.get_setpoint())\n",
    "\t\tstate, reward, _ = env.step(power)\n",
    "\tdqn_dev[i] = deviation_sum / sim_max\n",
    "\tdqn_cycles[i] = cycles\n",
    "\tprint(f\"{i + 1}/{episode_count}\", end=\"\\r\")\n",
    "\n",
    "print(\"             \", end=\"\\r\")\n",
    "for i in range(episode_count):\n",
    "\tdeviation_sum = 0\n",
    "\t# weather_start = 0\n",
    "\tweather_start = random.randrange(0, len(const.OUTSIDE_TEMP) - sim_max)\n",
    "\tstate, _ = env.reset(num_setpoints=num_setpoints, length=sim_max, start_time=weather_start)\n",
    "\told_action = 0\n",
    "\tcycles = 0\n",
    "\tfor t in range(sim_max):\t\n",
    "\t\tpower = agents.dumb_agent.agent(env.get_cur_temp(), const.OUTSIDE_TEMP[weather_start + t], env.get_setpoint(), env._actions[old_action])\n",
    "\t\tpower = env._actions.index(power)\n",
    "\t\tif env._sgn(power) != env._sgn(old_action):\n",
    "\t\t\tcycles += 1\n",
    "\t\told_action = power\n",
    "\n",
    "\t\tdeviation_sum += abs(env.get_cur_temp() - env.get_setpoint())\n",
    "\t\tstate, reward, _ = env.step(power)\n",
    "\tstupid_dev[i] = deviation_sum / sim_max\n",
    "\tif deviation_sum / sim_max > 11:\n",
    "\t\tprint(\"VERY BAD\", weather_start)\n",
    "\tstupid_cycles[i] = cycles\n",
    "\tprint(f\"{i + 1}/{episode_count}\", end=\"\\r\")\n",
    "\n",
    "ax1.plot(xvalues, dqn_dev, linewidth=0.5, color=\"blue\")\n",
    "# ax2.plot(xvalues, dqn_cycles, linewidth=0.5, color=\"purple\")\n",
    "ax1.plot(xvalues, stupid_dev, linewidth=0.5, color=\"orange\")\n",
    "# ax2.plot(xvalues, stupid_cycles, linewidth=0.5, color=\"red\")\n",
    "plt.savefig(\"out.png\", dpi=1000)\n",
    "\n",
    "print(f\"dqn dev mean {np.mean(dqn_dev)}\")\n",
    "print(f\"dqn dev median {np.median(dqn_dev)}\")\n",
    "print(f\"dqn dev min {np.min(dqn_dev)}\")\n",
    "print(f\"dqn dev max {np.max(dqn_dev)}\")\n",
    "\n",
    "print(f\"dqn cycle mean {np.mean(dqn_cycles)}\")\n",
    "print(f\"dqn cycle median {np.median(dqn_cycles)}\")\n",
    "print(f\"dqn cycle min {np.min(dqn_cycles)}\")\n",
    "print(f\"dqn cycle max {np.max(dqn_cycles)}\")\n",
    "\n",
    "print(f\"stupid dev mean {np.mean(stupid_dev)}\")\n",
    "print(f\"stupid dev median {np.median(stupid_dev)}\")\n",
    "print(f\"stupid dev min {np.min(stupid_dev)}\")\n",
    "print(f\"stupid dev max {np.max(stupid_dev)}\")\n",
    "\n",
    "print(f\"stupid cycle mean {np.mean(stupid_cycles)}\")\n",
    "print(f\"stupid cycle median {np.median(stupid_cycles)}\")\n",
    "print(f\"stupid cycle min {np.min(stupid_cycles)}\")\n",
    "print(f\"stupid cycle max {np.max(stupid_cycles)}\")\n",
    "\n",
    "# m2K/W * m2 * K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params = sum(p.numel() for p in policy_net.parameters() if p.requires_grad)\n",
    "pytorch_total_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
